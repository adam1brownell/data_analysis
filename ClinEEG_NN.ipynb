{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### NN Predictor with prior distribution (or recency) sampling ###\n",
    "##################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data, condensed as we did this previously\n",
    "def load_clinical_eeg_data(datapath, sub):\n",
    "    import pandas as pd\n",
    "    alldata = pd.read_csv(os.path.join(datapath, sub + '.csv')) #removed 'train' bc of how I saved\n",
    "    alldata.rename(columns={'Unnamed: 0': 'Index'})\n",
    "    eegevents = alldata[['labels', 'chunks']]\n",
    "    alldata.drop(['Unnamed: 0', 'labels', 'chunks'], axis=1, inplace=True)\n",
    "    names = alldata.keys()\n",
    "    return alldata.iloc[:].as_matrix(), eegevents, names\n",
    "import os\n",
    "import numpy as np\n",
    "os.chdir(\"C:\\\\Users\\\\adam1brownell\\\\Desktop\\Winter2017\\\\188B Files\\Project\")\n",
    "path = os.getcwd()\n",
    "\n",
    "#Get subject names from appropriate dir, -4 for .csv suffux\n",
    "subjects = [f[:-4] for f in os.listdir(path)]\n",
    "\n",
    "data, label_chunk, nodes = load_clinical_eeg_data(path,subjects[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Relabel the data so that we can train our model properly\n",
    "import numpy as np\n",
    "label = np.array(label_chunk)[:,0]\n",
    "#For now...\n",
    "pLabel = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into train/test\n",
    "# data = data, pLabel = labels\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, pLabel, test_size=.2)\n",
    "\n",
    "\n",
    "#Specify Hidden Layers\n",
    "#There are 23 nodes, so input could be 23 nodes (or smaller) and output is 3 nodes\n",
    "#Hidden layers are 10 and 5, like keras intro stated\n",
    "layer_sizes = [10, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    }
   ],
   "source": [
    "#Build NN\n",
    "from keras.models import Sequential\n",
    "NNmodel = Sequential()\n",
    "\n",
    "#Add layers\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "#Input Layer -> 1\n",
    "NNmodel.add(Dense(input_dim=X_train.shape[1], output_dim=layer_sizes[0]))\n",
    "NNmodel.add(Activation('sigmoid'))\n",
    "#Hidden Layer 1 -> 2\n",
    "NNmodel.add(Dense(input_dim=layer_sizes[0], output_dim=layer_sizes[1]))\n",
    "NNmodel.add(Activation('sigmoid'))\n",
    "#Hidden Layer 2 -> output\n",
    "NNmodel.add(Dense(output_dim=np.unique(y_train).shape[0], init='uniform'))\n",
    "NNmodel.add(Activation('softmax'))\n",
    "\n",
    "# Next we let the network know how to learn\n",
    "#(From Keras doc)\n",
    "from keras.optimizers import SGD\n",
    "sgd = SGD(lr=0.001, decay=1e-7, momentum=.9)\n",
    "NNmodel.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "# Before we can fit the network, we have to one-hot vectorize our response.\n",
    "# Fortunately, there is a keras method for that.\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train_vectorized = to_categorical(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "258969/258969 [==============================] - 118s - loss: 0.3016   \n",
      "Epoch 2/3\n",
      "258969/258969 [==============================] - 116s - loss: 0.2957   \n",
      "Epoch 3/3\n",
      "258969/258969 [==============================] - 117s - loss: 0.2957   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xf0f9240>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model\n",
    "NNmodel.fit(X_train, y_train_vectorized, nb_epoch=3, batch_size=50)\n",
    "#NNmodel.fit(X_train, y_train_vectorized, nb_epoch=1000, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.91337603,  0.08662394]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#probability of 1 sample\n",
    "NNmodel.predict_proba(np.reshape(X_test[1,:], (1,23)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64192/64743 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91268554129403956"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#score model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, NNmodel.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#I want to take the prob of it being before a seizure and add it to a distribution to find the true probability\n",
    "def ten_sec(model,datapoint,prior,i):\n",
    "    #This is the NN predict without considering time context:\n",
    "    prop = model.predict_proba(datapoint)\n",
    "    #Augment prediction based on Context\n",
    "    \n",
    "    prior[i] = prop\n",
    "    #skepticism:\n",
    "    skept_prop = np.mean(prior)\n",
    "    return skept_prior\n",
    "    #If previous mean AND current prediction are above threshold, then higher probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get predict_proba for all datapoints\n",
    "#For every data point\n",
    "#If the previous prediction agrees with current point:\n",
    "    #Augment probability by \"congruency value\"\n",
    "#Else\n",
    "    #Augement probability by \"discongruency vale\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64096/64743 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This part shows that despite getting 92% accuracy, we are still only at chance guessing\n",
    "#This is because our NN learns to always guess \"no eizure\" since seizures are so rare\n",
    "\n",
    "proba = NNmodel.predict_proba(X_test, batch_size=32)\n",
    "classes = np.argmax(proba, axis=1)\n",
    "import sklearn.metrics as met\n",
    "res = NNmodel.predict(X_test)\n",
    "met.roc_auc_score(y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "4046/4046 [==============================] - 1s - loss: 0.2999     \n",
      "Epoch 2/3\n",
      "4046/4046 [==============================] - 1s - loss: 0.2999     \n",
      "Epoch 3/3\n",
      "4046/4046 [==============================] - 2s - loss: 0.2997     \n",
      " 480/1012 [=============>................] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.91600790513833996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Retesting the NN with the max freq per second\n",
    "def take_max_every_64_points(x):\n",
    "    i=0; \n",
    "    mean_array=[]\n",
    "    while(i<(x.shape[0])):\n",
    "        array=x[i:i+65]\n",
    "        mean_array.append(np.max(array))\n",
    "        i+=64\n",
    "    mean_array=np.array(mean_array)\n",
    "    return mean_array\n",
    "dataset20 = np.apply_along_axis(take_max_every_64_points,0,data)\n",
    "y20=take_max_every_64_points(np.array(label_chunk)[:,0])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset20, y20, test_size=.2)\n",
    "y_train_vectorized = to_categorical(y_train)\n",
    "\n",
    "NNmodel.fit(X_train, y_train_vectorized, nb_epoch=3, batch_size=50)\n",
    "accuracy_score(y_test, NNmodel.predict_classes(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 576/1012 [================>.............] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Still at chance...\n",
    "proba = NNmodel.predict_proba(X_test, batch_size=32)\n",
    "classes = np.argmax(proba, axis=1)\n",
    "import sklearn.metrics as met\n",
    "res = NNmodel.predict(X_test)\n",
    "met.roc_auc_score(y_test, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replacing chunk numbers with their indexes\n",
    "chunks = np.array(label_chunk)[:,1]\n",
    "labels = np.array(label_chunk)[:,0]\n",
    "\n",
    "\n",
    "chunks_numbers = np.unique(chunks, return_index=True)\n",
    "\n",
    "i = 1\n",
    "new_chunks = []\n",
    "total_chunks = chunks_numbers[0].shape[0]\n",
    "\n",
    "while i < total_chunks:\n",
    "    for j in range(chunks_numbers[1][i-1], chunks_numbers[1][i]):\n",
    "        new_chunks.append(i-1)\n",
    "    i += 1\n",
    "for j in range(chunks_numbers[1][total_chunks-1], chunks.shape[0]):\n",
    "    new_chunks.append(i-1)\n",
    "new_chunks = np.array(new_chunks)\n",
    "# print new_chunks.shape\n",
    "# chunks_numbers = np.unique(new_chunks, return_index=True)\n",
    "# print chunks_numbers\n",
    "chunks = new_chunks\n",
    "\n",
    "\n",
    "# creating new labels for seizure, pre- and post- seizure\n",
    "# in each chunk - 10 minutes before/after sezure = 600 samples X 599\n",
    "# -1 = pre, 1 = seizure, 0 = post\n",
    "\n",
    "#print labels.shape\n",
    "chunks_numbers = np.unique(chunks, return_index=True)\n",
    "#(array([0, 1, 2, 3, 4, 5]), array([   0, 1203, 2430, 3670, 4921, 6211]))\n",
    "\n",
    "i = 1\n",
    "while i < total_chunks:\n",
    "    start = chunks_numbers[1][i-1]\n",
    "    end = chunks_numbers[1][i]-1\n",
    "    for j in range(start, end):\n",
    "        labels[j] = -1\n",
    "        if labels[j+1] == 1:\n",
    "            break\n",
    "    i += 1\n",
    "\n",
    "start = end + 1\n",
    "end = labels.shape[0]\n",
    "for j in range(start, end):\n",
    "    labels[j] = -1\n",
    "    if labels[j+1] == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,  72448, 156288, 239232], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chunks_numbers[1] = chunk cutoffs\n",
    "# total_chunks = number of chunks\n",
    "chunks_numbers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def re_label(chunks,labels):\n",
    "    pLabel = [0 for i in range(len(labels))]\n",
    "    \n",
    "    #For every chunk\n",
    "    for i in range(total_chunks):\n",
    "        \n",
    "        #If on the last chunk set limit to end of all data, else set to beginning of next chunk\n",
    "        if i == 3:\n",
    "            limit = len(labels)\n",
    "        else:\n",
    "            limit = chunks_numbers[1][i+1]\n",
    "\n",
    "        #flag for seizure occuring now, set to false\n",
    "        seiz_rn = False\n",
    "\n",
    "\n",
    "        #Looking at all values within a chunk\n",
    "        for datapoint in range(i,limit):\n",
    "\n",
    "            #If no seizure rn and none before, add 0\n",
    "            if labels[datapoint] == 0 and seiz_rn == False:\n",
    "                pLabel[datapoint] = 0 #I don't need this since it already is set to 0 but kept for readibility\n",
    "\n",
    "            #If seizure rn and yes before, add 1\n",
    "            elif labels[datapoint] == 1 and seiz_rn == True:\n",
    "                pLabel[datapoint] = 1\n",
    "\n",
    "            #If seizure rn and none before, add 1 AND change the last 640 (10sec) of pLabel to 2\n",
    "            elif labels[datapoint] == 1 and seiz_rn == False:\n",
    "                for j in range(datapoint-640,datapoint+1):\n",
    "                    pLabel[j] = 2\n",
    "                seiz_rn = True\n",
    "\n",
    "            #If label is 0 and seiz is true, seiz just ended\n",
    "            else:\n",
    "                pLabel[datapoint] = 0 #Don't need, just for reading\n",
    "                seiz = False\n",
    "                \n",
    "    return pLabel\n",
    "\n",
    "def re_label2(chunks,labels):\n",
    "    pLabel = [0 for i in range(len(labels))]\n",
    "    seiz_rn = False\n",
    "    for datapoint in range(len(labels)):\n",
    "        #If no seizure rn and none before, add 0\n",
    "        if labels[datapoint] == 0 and seiz_rn == False:\n",
    "            pLabel[datapoint] = 0 #I don't need this since it already is set to 0 but kept for readibility\n",
    "\n",
    "        #If seizure rn and yes before, add 1\n",
    "        elif labels[datapoint] == 1 and seiz_rn == True:\n",
    "                pLabel[datapoint] = 1\n",
    "\n",
    "        #If seizure rn and none before, add 1 AND change the last 640 (10sec) of pLabel to 2\n",
    "        elif labels[datapoint] == 1 and seiz_rn == False:\n",
    "            for j in range(datapoint-640,datapoint+1):\n",
    "                pLabel[j] = 2\n",
    "            seiz_rn = True\n",
    "\n",
    "        #If label is 0 and seiz is true, seiz just ended\n",
    "        else:\n",
    "            pLabel[datapoint] = 0 #Don't need, just for reading\n",
    "            seiz = False\n",
    "    \n",
    "    return pLabel        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pLabel = re_label2(chunks,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
